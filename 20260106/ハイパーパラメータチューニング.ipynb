{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yajima-yasutoshi/DataScience2025/blob/main/20260106/%E3%83%8F%E3%82%A4%E3%83%91%E3%83%BC%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF%E3%83%81%E3%83%A5%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ハイパーパラメータチューニング"
      ],
      "metadata": {
        "id": "Dd5Plw8hVnrA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#本日の講義の目的\n",
        "\n",
        "回帰や分類などの予測モデル構築で、\n",
        "予測精度を向上させるテクニックとして良く知られた\n",
        "**正則化パラメータチューニング**について説明する。\n",
        "なお、これは一般的に\n",
        "**ハイパーパラメータチューニング**\n",
        "と呼ばれるものの一つであり、\n",
        "機械学習モデルの精度向上には欠かせないテクニックである。\n"
      ],
      "metadata": {
        "id": "wUezl4MyB_v3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 環境の準備\n",
        "以下のコードセルを実行し、\n",
        "日本語の表示を行うための設定と分析に必要なパッケージのインポートを行う。"
      ],
      "metadata": {
        "id": "7uEdwaOOxjsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 日本語環境のインストール\n",
        "!pip install japanize-matplotlib\n",
        "\n",
        "# 必要なライブラリをインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "# 分析に必要なライブラリのインポート\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 回帰に必要なライブラリをインポート\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 分類（ロジスティック回帰）に必要なライブラリー\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 精度評価に必要なライブラリー\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# その他必要なライブラリー\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "g9TNYrU66eru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "VR-S5kvXdKbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ロジスティック回帰でのハイパーパラメータチューニング\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TKlOXVFpJj7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Titanic データの読み込み\n",
        "\n",
        "以下のコードセルを実行することで、\n",
        "seaborn パッケージに含まれているデモデータの一つである、\n",
        "Titanic データを読み込む。"
      ],
      "metadata": {
        "id": "PkNPXYJHgiRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを読み込む\n",
        "# 変数名を data とした\n",
        "data = sns.load_dataset('titanic') #タイタニックのデータ"
      ],
      "metadata": {
        "id": "j_M6pfGUdT3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###データの構造の確認"
      ],
      "metadata": {
        "id": "n_T7sNP7hwML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "info を使い、データの構造を確認する。"
      ],
      "metadata": {
        "id": "knxiSxQ_r2nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "bk9LG_iFg9Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "レコード数は891、項目数は15、欠損値を含む列も複数あることが分かる。"
      ],
      "metadata": {
        "id": "7wJW7GuMt9Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)"
      ],
      "metadata": {
        "id": "45yqvqg1iBhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##データの説明と分析の目的\n",
        "\n",
        "このデータは、\n",
        "1912年に発生したタイタニック号の沈没事故の乗客情報のデータである。\n",
        "各項目の意味は以下の通りである。\n",
        "\n",
        "列名 | 型 | 意味\n",
        "---  | --- | --\n",
        "survived\t| カテゴリ | 生存フラグ（0=死亡、1=生存）\n",
        "pclass\t|  カテゴリ |チケットクラス（1stクラス、2ndクラス、3rdクラス）＊classと同じ内容のため用いない\n",
        "sex\t|  カテゴリ |性別（male：男性、female：女性）\n",
        "sge\t|  数値 |年齢\n",
        "sibsp\t|  数値 |タイタニックに同乗している兄弟/配偶者の数\n",
        "parch\t|  数値 |タイタニックに同乗している親/子供の数\n",
        "fare\t|  数値 |料金\n",
        "embarked\t|  カテゴリ |出港地（タイタニックへ乗った港）(C=Cherbourg、Q=Queenstown、S=Southampton)\n",
        "class |  カテゴリ |乗船クラス\n",
        "who | カテゴリ |男性 or 女性\n",
        "adult_male |  カテゴリ |成人男性であるかどうか\n",
        "deck |  カテゴリ |乗船していたデッキ\n",
        "embark_town |  カテゴリ |出港地 ＊embarked と同じ内容のため用いない\n",
        "alive |  カテゴリ |生存したかどうか ＊survived と同じ内容ため用いない\n",
        "alone |  カテゴリ |一人であったかどうか\n"
      ],
      "metadata": {
        "id": "t7UJupBadfY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このデータを学習用データとして用い、\n",
        "**乗客の生存を予測するAIモデル**を作成する。"
      ],
      "metadata": {
        "id": "ripSfbtwtp6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 前処理\n",
        "欠損値の確認を行う。"
      ],
      "metadata": {
        "id": "sxvvu9emqE2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 欠損値を確認する\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "3mFcWAqQd0qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上の結果より、\n",
        "このデータには age, embarked, deck などに欠損値が含まれていることがわかる。\n",
        "\n",
        "age は数値型の項目であることから、欠損した部分を平均値で埋めることにする。\n",
        "また embarked はカテゴリ型の項目であることから、\n",
        "最頻値を使い欠損値を埋めることとする。\n",
        "\n",
        "さらに、deck は欠損値が多数あるため、説明変数としては用いないこととする。\n"
      ],
      "metadata": {
        "id": "Mt96IBOHsQtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# age, embarked, の欠損値を埋める。\n",
        "# deck は欠損値が多数あるため説明変数には用いないことにする。\n",
        "\n",
        "# age は数値型なので、平均値で欠損値を埋める。\n",
        "data['age'] = data['age'].fillna(data['age'].mean())\n",
        "\n",
        "# カテゴリ型の項目は、最頻値で欠損値を埋める。\n",
        "data['embarked'] = data['embarked'].fillna(data['embarked'].mode()[0])\n",
        "data['embark_town'] = data['embark_town'].fillna(data['embark_town'].mode()[0])\n",
        "\n",
        "# 結果を確認\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "_jzkQkrvd8kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 基礎集計\n",
        "\n",
        "どのような属性の乗客が生存率が高いのか（低いのか）を調べるため、\n",
        "基礎集計として以下のコードセルを実行する。\n",
        "なお、それぞれの結果を表示させるため print() を付与している。"
      ],
      "metadata": {
        "id": "YzV1YdeoqSYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 表示する桁数を指定\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "# 基本的な統計情報を表示\n",
        "print(\"\\n数値型の項目に対する統計量の表示\")\n",
        "print( data.describe() )\n",
        "\n",
        "# 目的変数の確認（生存者数と死亡者数を集計）\n",
        "survived_counts = data['survived'].value_counts()\n",
        "print(\"\\n生存者数と死亡者数の集計:\")\n",
        "print(survived_counts)\n",
        "\n",
        "# 乗客のクラスごとの生存率を計算\n",
        "survival_rate_by_class = data.groupby('class')['survived'].mean()\n",
        "print(\"\\nクラスごとの生存率:\")\n",
        "print(survival_rate_by_class)\n",
        "\n",
        "# 性別ごとの生存率を計算\n",
        "survival_rate_by_gender = data.groupby('sex')['survived'].mean()\n",
        "print(\"\\n性別ごとの生存率:\")\n",
        "print(survival_rate_by_gender)\n"
      ],
      "metadata": {
        "id": "vQPkr1kMdog4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ロジスティック回帰モデルの構築"
      ],
      "metadata": {
        "id": "ceIrckdNnYgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず、数値型の項目のみでモデルを作成し精度を確認する。"
      ],
      "metadata": {
        "id": "BuKY6xQ8ndgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 説明変数と目的変数を選択\n",
        "# 数値データのみで予測\n",
        "X = data[[ 'age', 'fare', 'sibsp', 'parch']]\n",
        "y = data[['survived']]"
      ],
      "metadata": {
        "id": "ulgIt8EvebAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データを学習用と検証用に分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 説明変数の標準化の準備\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# 標準化後のものは別の変数にセットすると良い\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# ロジスティック回帰モデルの準備\n",
        "model = LogisticRegression()\n",
        "\n",
        "# モデルを訓練\n",
        "model.fit(X_train_scaled, y_train.values.ravel()  )\n",
        "\n",
        "# テストデータで予測\n",
        "y_pred = model.predict(X_val_scaled)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "id": "q1GBsffU5UGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 回帰係数\n",
        "\n",
        "回帰係数の正負は、以下の意味合いがある。\n",
        "\n",
        "* 回帰係数が正：大きいほど 1 （生存） になりやすい。（小さいほど0になりやすい）\n",
        "* 回帰係数が負：大きいほど 0 （死亡） になりやすい。（小さいほど1になりやすい）"
      ],
      "metadata": {
        "id": "NtjCwWAUTo7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 回帰係数を可視化\n",
        "sns.barplot(x=model.coef_[0], y=X.columns)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "hKKGs7fv7_DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## カテゴリ型の項目も追加してモデルを構築"
      ],
      "metadata": {
        "id": "dzOB0cwfvJfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# カテゴリ変数をOne Hot Encoding\n",
        "data_encoded = pd.get_dummies(data[['embarked', 'class', 'who', 'adult_male', 'alone']], drop_first=True)\n",
        "\n",
        "# 説明変数と目的変数を設定\n",
        "X = pd.concat([data[['age', 'fare', 'sibsp', 'parch']], data_encoded], axis=1)\n",
        "y = data['survived']"
      ],
      "metadata": {
        "id": "OzUk33bJn2j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データを学習用データと検証用データに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 準備のための手順\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# 標準化後のものは別の変数にセットすると良い\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# ロジスティック回帰モデルを作成\n",
        "model = LogisticRegression()\n",
        "\n",
        "# モデルを訓練\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# テストデータで予測\n",
        "y_pred = model.predict(X_val_scaled)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "7q1cK6gYe_LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "カテゴリ項目を説明変数に加えることで、精度が向上したことが分かる。"
      ],
      "metadata": {
        "id": "Eoi4x14f_LU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 回帰係数を可視化\n",
        "sns.barplot(x=model.coef_[0], y=X.columns)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d5tZtxJb9YBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ハイパーパラメータチューニング"
      ],
      "metadata": {
        "id": "ZjFF5JlDMVbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 正則化パラメータ\n",
        "\n",
        "ロジスティック回帰モデルには、\n",
        "「正則化パラメータ」と呼ばれる値を設定する必要があり、\n",
        "準備段階で、例えば以下のように指定する。\n",
        "\n",
        "```\n",
        "model = LogisticRegression(C=1.0)\n",
        "```\n",
        "\n",
        "C=1.0\n",
        "の部分を変更することで精度をより向上させることが可能である。\n",
        "\n",
        "\n",
        "なお、指定を省略した場合には、\n",
        "デフォルトとして C=1.0 が指定される。\n",
        "\n",
        "\n",
        "正則化パラメータとして、どの値が適切かを調べるために\n",
        "**グリッドサーチ**と呼ばれる方法がある。\n",
        "\n",
        "まず、正則化パラメータの候補を、\n",
        "例えば、以下のように辞書型の変数を設定する。\n",
        "\n",
        "```\n",
        "param_grid = {'C': [ 0.1, 0.15, 0.2, 0.3, 1, 2]}\n",
        "```\n",
        "正則化パラメータの候補は正の値で、\n",
        "多くの場合は 0.1 ～ 100の範囲とすると良いことが知られている。\n",
        "\n",
        "このように設定した候補の中から、\n",
        "最も良いハイパーパラメータを選び出す方法を**グリッドサーチ**と呼び、\n",
        "そためのモジュールが用意されている。\n",
        "\n",
        "モジュールは、以下のようにインポートする。\n",
        "```\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "```\n",
        "\n",
        "候補を設定したら、GridSearchCV を以下のように初期化し、\n",
        "その後 fit() で計算を実行する。\n",
        "\n",
        "```\n",
        "#グリッドサーチの準備\n",
        "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "\n",
        "#グリッドサーチの実行\n",
        "grid_search.fit(X_train_scaled, y_train.values.ravel() )\n",
        "```\n",
        "\n",
        "実行した結果、最適なハイパーパラメータのモデルは以下の変数に格納される。\n",
        "```\n",
        "grid_search.best_estimator_\n",
        "```"
      ],
      "metadata": {
        "id": "tgp-VQa-7uy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリをインポート\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# パラメータグリッドを設定\n",
        "param_grid = {'C': [ 0.1, 0.15, 0.2, 0.3, 0.5]}\n",
        "\n",
        "# GridSearchCVを初期化\n",
        "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "\n",
        "# グリッドサーチを実行\n",
        "grid_search.fit(X_train_scaled, y_train.values.ravel() )\n",
        "\n",
        "# 最適なハイパーパラメータのモデルでテストデータを評価\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train_scaled, y_train.values.ravel() )\n",
        "\n",
        "y_pred = best_model.predict(X_val_scaled)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"Validation set accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "n6sbG3umqaqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "grid_search.best_params_ には、最適なパラメータが格納されている。"
      ],
      "metadata": {
        "id": "pYyhP8WkW-NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 最適なパラメータとスコアを出力\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "# print(f\"Best cross-validation score: {grid_search.best_score_}\")"
      ],
      "metadata": {
        "id": "OJHSUT9GWTlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title グリッドサーチの内部処理\n",
        "scores = grid_search.cv_results_['mean_test_score']\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x=param_grid['C'], y=scores)\n",
        "plt.xlabel('C (Inverse of regularization strength)')\n",
        "plt.ylabel('Mean Test Score')\n",
        "plt.title('Grid Search の様子')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M2kdwcnChhPA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "eb2GYJAz5z_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 回帰モデルに対するハイパーパラメータの調整\n"
      ],
      "metadata": {
        "id": "s2RJbJOorRlC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "回帰モデルに対してもハイパーパラメータチューニングを行い精度の向上を図ることが可能である。\n",
        "ここでは、Ridge 回帰と呼ばれる方法を使い、\n",
        "ハイパーパラメータチューニングを行う。"
      ],
      "metadata": {
        "id": "CnotTrmFQUAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tipsデータ\n",
        "\n",
        "ここでは Tipsデータを用いて説明を行う。\n",
        "Tips データは、\n",
        "seaborn パッケージに含まれているデモデータで、\n",
        "以下のコードセルを実行することで\n",
        "変数 df_tips に読み込まれる。"
      ],
      "metadata": {
        "id": "yPWzW72gRQVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seaborn import load_dataset\n",
        "# データの読み込み\n",
        "df_tips = sns.load_dataset('tips')"
      ],
      "metadata": {
        "id": "jgL1kI3dRwoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tipsデータの概要を info で確認する。"
      ],
      "metadata": {
        "id": "ZSKsBLSDSFzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tips.info()"
      ],
      "metadata": {
        "id": "pX9aUCInSMMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG_9cxNiPCDr"
      },
      "source": [
        "### データの説明\n",
        "このデータは、あるレストランでのチップ金額（tip）のデータである。\n",
        "\n",
        "主な項目は以下の通り。\n",
        "\n",
        "項目 | 型 | 説明\n",
        "-- | -- | --\n",
        "total_bill | 数値 | 食事代の総額\n",
        "tip        | 数値 | チップの額\n",
        "sex        | カテゴリ | 性別\n",
        "smoker     | カテゴリ | 喫煙者かどうか\n",
        "day        | カテゴリ | 曜日\n",
        "time       | カテゴリ | 時間帯が昼か夜か\n",
        "size       | 数値 | 顧客サイズ（グループの人数）\n",
        "\n",
        "\n",
        "このデータを使い、チップ金額を予測する回帰モデルを作ってみる。\n",
        "すなわち\n",
        "\n",
        "* 目的変数：チップ金額（tip）\n",
        "* 説明変数：食事代の総額（total_bill）、グループの人数（size）、性別（sex）、など\n",
        "\n",
        "である。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "データの先頭を表示する。"
      ],
      "metadata": {
        "id": "-MKLzrJtUflf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCEQH1KZPCDr"
      },
      "outputs": [],
      "source": [
        "# データの先頭を表示して確認\n",
        "df_tips.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 分析用データの準備\n",
        "\n",
        "データの準備として、以下の処理を行う。\n",
        "\n",
        "\n",
        "*   カテゴリ項目を One-Hot エンコーディング を使い数値型の項目変換\n",
        "*   変数の標準化\n",
        "\n",
        "以下のコードセルを実行することで、標準化した説明変数が\n",
        "X_trans にセットされる。"
      ],
      "metadata": {
        "id": "Sqxx25TeRHHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 標準化に必要なライブラリーのインポート\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# データの読み込み\n",
        "df_tips = sns.load_dataset('tips')\n",
        "\n",
        "# カテゴリ変数をOne-Hotエンコーディング\n",
        "encoded_df_tips = pd.get_dummies(df_tips[['sex', 'smoker', 'day', 'time']])\n",
        "\n",
        "# エンコードされたデータと元のデータを結合\n",
        "df_tips = pd.concat([df_tips, encoded_df_tips], axis=1)\n",
        "\n",
        "# 説明変数 X と 目的変数 y をセットする\n",
        "X = df_tips[['total_bill', 'size', 'sex_Male', 'sex_Female', 'smoker_Yes', 'smoker_No', 'day_Thur', 'day_Fri', 'day_Sat', 'day_Sun', 'time_Lunch', 'time_Dinner']]\n",
        "y = df_tips['tip']\n",
        "\n",
        "# 標準化の実施\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "# 標準化後のデータを X_trans\n",
        "X_trans = scaler.transform(X)\n"
      ],
      "metadata": {
        "id": "E6kmE2ezrRlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ridge 回帰\n",
        "\n",
        "回帰モデルの一つである Ridge 回帰を使い、\n",
        "ハイパーパラメータチューニングを行う。\n",
        "\n",
        "Ridge 回帰には、「正則化パラメータ」があり、\n",
        "例えば、以下のように指定する。\n",
        "```\n",
        "model = Ridge( alpha =1.0 )\n",
        "```\n",
        "alpha に様々な数値を設定することで精度をより向上させることが可能である。\n",
        "\n",
        "以下のコードセルで、\n",
        "正則化パラメータ―を変化させると、精度が変化することを確認せよ。\n"
      ],
      "metadata": {
        "id": "coN5tSwAUQrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリをインポート\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# データを学習データと検証データに分割\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(X_trans, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Ridge(alpha=10)\n",
        "model.fit(X_train, y_train.values.ravel() )\n",
        "\n",
        "# 評価データで精度を確認する\n",
        "y_pred = model.predict(X_validate)\n",
        "# 決定係数による評価（R2）\n",
        "r2 = r2_score(y_validate, y_pred)\n",
        "print('R2: ', r2)"
      ],
      "metadata": {
        "id": "mgUBjkk-psEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RidgeCV というモジュールを用いることで、\n",
        "以下のような簡潔なコードでハイパーパラメータチューニングを行うことが可能である。\n"
      ],
      "metadata": {
        "id": "ikatnCyp0-x0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "# データを学習データと検証データに分割\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(X_trans, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RidgeCV()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 評価データで精度を確認する\n",
        "# 決定係数による評価（R2）\n",
        "r2 = model.score(X_validate, y_validate)\n",
        "print('R2: ', r2)"
      ],
      "metadata": {
        "id": "IgfQES3-r-6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "リッジ回帰をさらに複雑化した回帰手法に、\n",
        "エラスティックネット（ElasticNet）がある。\n",
        "以下のように使う。"
      ],
      "metadata": {
        "id": "zbVBP-AOA3UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNetCV\n",
        "\n",
        "# データを学習データと検証データに分割\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(X_trans, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = ElasticNetCV()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 評価データで精度を確認する\n",
        "# 決定係数による評価（R2）\n",
        "r2 = model.score(X_validate, y_validate)\n",
        "print('R2: ', r2)"
      ],
      "metadata": {
        "id": "aPLF-hoO37Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "この例では、さらに精度の高いモデルが構築できた。\n",
        "\n"
      ],
      "metadata": {
        "id": "W2L0Ean7BVRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## その他の回帰モデル\n",
        "\n",
        "回帰モデルには、ここでは扱わなかった多くのモデルがある。\n",
        "各自で以下のサイトを参照し、実際に使ってみる。\n",
        "\n",
        "https://scikit-learn.org/1.5/api/sklearn.linear_model.html"
      ],
      "metadata": {
        "id": "ekWux6lPB2bs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# その他の参考となるサイト\n",
        "\n",
        "インターネット上には、様々なデータが公開されている。\n",
        "各自で予測モデル構築に取り組んでみる。\n",
        "\n",
        "* https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package\n",
        "\n",
        "* https://www.kaggle.com/datasets/yeanzc/telco-customer-churn-ibm-dataset\n"
      ],
      "metadata": {
        "id": "XZNhEBfLmwHZ"
      }
    }
  ]
}