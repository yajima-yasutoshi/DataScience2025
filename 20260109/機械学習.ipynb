{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DSwFQUGOD0iT"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yajima-yasutoshi/DataScience2025/blob/main/20260109/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 機械学習"
      ],
      "metadata": {
        "id": "DSwFQUGOD0iT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#講義の目的\n",
        "\n",
        "機械学習による分類手法に関する説明を行う。\n",
        "代表的な手法である\n",
        "**決定木**および**ランダムフォレスト**\n",
        "と呼ばれる2つの分類モデルの構築法を理解する。\n"
      ],
      "metadata": {
        "id": "wUezl4MyB_v3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 準備\n"
      ],
      "metadata": {
        "id": "8zFBC9q961jw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 日本語環境のインストールと必要なライブラリーのインポート"
      ],
      "metadata": {
        "id": "ZcX_E1F-64Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 日本語環境のインストール\n",
        "!pip install japanize-matplotlib\n",
        "\n",
        "# 必要なライブラリをインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# 決定木に必要なライブラリー\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "# ランダムフォレストに必要なライブラリー\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# その他必要なライブラリー\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "g9TNYrU66eru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cancer データ"
      ],
      "metadata": {
        "id": "gRs3b9V4wBaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データの概要確認\n",
        "\n",
        "sklean ライブラリーに格納されているサンプルデータ（cancer data）を使い、\n",
        "**決定木**の説明を行う。\n",
        "以下のコードセルでは、データをデータフレーム df にセットし、\n",
        "info() を使い概要を表示する。"
      ],
      "metadata": {
        "id": "THzc4_hPdU3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "df = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
        "df['diagnosis'] = cancer.target\n",
        "\n",
        "#データの概要を表示\n",
        "df.info()"
      ],
      "metadata": {
        "id": "bPDzMK4uN0IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cancer データ とは、\n",
        "30項目の細胞に関連したデータ（サイズ、形状、など）と\n",
        "そこから判断された癌の診断結果（'diagnosis'）のデータである。\n",
        "\n",
        "全ての項目は数値型で、\n",
        "特に診断結果（'diagnosis'）は\n",
        "\n",
        "* 悪性の場合には 0\n",
        "* 良性の場合には 1\n",
        "\n",
        "が入力されており、\n",
        "このような項目を**2値**の項目と呼ぶ。\n",
        "\n",
        "このデータを学習させて、**癌の診断（良性か悪性かの分類）を行うAIを構築**する。"
      ],
      "metadata": {
        "id": "LdH53ARgIepY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 目的変数の確認\n",
        "\n",
        "まず初めに、目的変数となる項目 diagnosis が2値となっていることを確認する。"
      ],
      "metadata": {
        "id": "vO3Wq2oqMfnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "id": "FW_ER1W5-b3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "項目 diagnosis は数値型の項目ではあるが、値は 0 と 1 の2値となっていることが確かめられる。\n",
        "よって、\n",
        "diagnosis は、2 値の分類問題の目的変数として利用が可能である。"
      ],
      "metadata": {
        "id": "ZUq7hgo472nI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 説明変数の確認と目的変数の関連\n",
        "\n",
        "ヒストグラムを作成して、各項目の分布を確認する。\n",
        "hue を使い目的変数の項目（diagnosis）で色分けしてみる。"
      ],
      "metadata": {
        "id": "F-qS51aHhHhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=df, x='mean radius', hue='diagnosis', kde=True)"
      ],
      "metadata": {
        "id": "VNU4Aza-Dcie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "diagnosis は、0 が悪性、1 が良性であった。\n",
        "このグラフからは、mean radius がおよそ18をこえるとほぼ全てが悪性、\n",
        "逆に10を下回るとほぼ全てが良性になっていることが分かる。\n",
        "一方で、10から18の間では、良性も悪性もあり、この項目だけでは\n",
        "悪性か良性かを判断できないが、\n",
        "これ以外の検査項目も説明変数に用いることで\n",
        "癌の診断を行うAIを作る。\n",
        "\n",
        "その他の説明変数に関しても各自で同様な確認を行う。\n"
      ],
      "metadata": {
        "id": "bG_bnzU9yk52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 決定木\n",
        "分類問題に対する代表的な機械学習の手法として、\n",
        "**決定木**の説明を行う。"
      ],
      "metadata": {
        "id": "kflta2TyOaRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 変数\n",
        "\n",
        "目的変数と説明変数は以下のとおりである。\n",
        "\n",
        "* **目的変数：** 予測の対象となる項目。上のデータでは diagnosis である。\n",
        "* **説明変数：** 予測する元になる項目。上のデータでは30項目の数値型データがある。\n",
        "\n",
        "\n",
        "なお、決定木の場合には、**説明変数の標準化は不要である**。\n"
      ],
      "metadata": {
        "id": "XECHEz4EhU7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##決定木モデルの学習"
      ],
      "metadata": {
        "id": "4I3xbCtTxWvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "説明変数と目的変数をそれぞれ変数 X と y にセットし、\n",
        "その後、\n",
        "train_test_split() を使い、全データを**学習用データ**と**検証用データ**に分割をする。"
      ],
      "metadata": {
        "id": "Spn955w6t_Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 項目'diagnosis'は変数dfの最後にある項目なので、それを除くと説明変数のみとなる\n",
        "X = df.iloc[:,:-1]\n",
        "y = df[['diagnosis']]\n",
        "\n",
        "# データを学習用データと検証用データに分割\n",
        "# test_size は、0.2 程度が良いとされる\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "pyHf_wHjOknH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "決定木の作成には、DecisionTreeClassifier() を用いて、\n",
        "以下のコードセルを実行する。\n"
      ],
      "metadata": {
        "id": "RkykhaigN0Wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 決定木に必要なライブラリー\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 決定木の準備\n",
        "model = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
        "\n",
        "# 学習\n",
        "model.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "rhyQN6dmeEWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "なお、max_depth は決定木のハイパーパラメータである。\n",
        "説明の都合ここでは max_depth = 2 として決定木を作るが、\n",
        "後ほど、ハイパーパラメータチューニングを行う。"
      ],
      "metadata": {
        "id": "cnQ9zAqDkPOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "決定木の内部では、以下の図に示すような\n",
        "予測がモデルが構築される。"
      ],
      "metadata": {
        "id": "4J3fhou1O_ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 決定木の可視化\n",
        "plt.figure(figsize=(16,5))\n",
        "plot_tree(model, filled=True, feature_names=cancer.feature_names, class_names=['0（悪性）','1（良性）'], fontsize=14)\n",
        "plt.title(\"Decision Tree of Cancer Dataset\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NMmARcJNDi9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "決定木モデルでは、説明変数の値の大小で\n",
        "上の図のように枝分かれしながら予測が行われる。\n",
        "箱の上に書かれた不等式に注目する。\n",
        "説明変数の値が不等式の条件を満たせば True と書かれた方向（左）、\n",
        "そうでなければ False と書かれた方向（右）方向に枝を下方向にたどりながら、\n",
        "最後に到達した箱の class が予測結果である。\n",
        "\n",
        "例えば、ある細胞のデータが、\n",
        "\n",
        "* worst concave points = 0.2\n",
        "* worst area = 700\n",
        "\n",
        "であった場合、上から枝をたどると、\n",
        "予測結果は class=1 (良性)と判定される。\n",
        "\n",
        "\n",
        "\n",
        "なお、上の例では、ハイパーパラメータである max_depth=2 と指定したので、\n",
        "二回枝分かれをするモデルになっている。\n",
        "また、枝分かれに用いられた項目は\n",
        "worst concave points\n",
        "と\n",
        "worst area\n",
        "の二つであった。\n",
        "他の説明変数の中から\n",
        "この二つが目的変数（この例では良性か悪性か）の判断に有効である、\n",
        "との結果になったことを意味している。\n"
      ],
      "metadata": {
        "id": "0HAiK8PQP1IP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "決定木の様子を、散布図を使って可視化すると以下のようになる。"
      ],
      "metadata": {
        "id": "PR9vnh4ZeDf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting with added lines\n",
        "sns.jointplot(x='worst concave points', y='worst area', data=df, hue='diagnosis')\n",
        "plt.axvline(x=0.142, color='red', linestyle='--')  # Add vertical line at x = 0.142\n",
        "plt.plot([-0.02, 0.142], [957.45, 957.45], color='red', linestyle='--') # Add line segment\n",
        "plt.plot([0.142,0.35], [729.55, 729.55], color='red', linestyle='--') # Add line segment\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uePNSsI7becI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=df, x='worst concave points', hue='diagnosis', kde=True)"
      ],
      "metadata": {
        "id": "gZpKmrf2GIVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=df, x='worst area', hue='diagnosis', kde=True)"
      ],
      "metadata": {
        "id": "abUwm9xtbUjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 評価用のデータを使い予測精度を確認する"
      ],
      "metadata": {
        "id": "XC28vVTzraqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "wGnlA5gerXf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "混同行列（confusion matrix）でも確認する。"
      ],
      "metadata": {
        "id": "eHhTt36wYUki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_val, y_pred)"
      ],
      "metadata": {
        "id": "rSOYxiTfX4ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Titanic データを使った例（決定木）"
      ],
      "metadata": {
        "id": "TKlOXVFpJj7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを読み込む\n",
        "data = sns.load_dataset(\"titanic\") #タイタニックのデータ\n",
        "data.info()\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "j_M6pfGUdT3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##データの説明\n",
        "\n",
        "列名 | 意味\n",
        "---  | ---\n",
        "survived\t| 生存フラグ（0=死亡、1=生存）\n",
        "pclass\t| チケットクラス（1stクラス、2ndクラス、3rdクラス）\n",
        "sex\t| 性別（male=男性、female＝女性）\n",
        "sge\t| 年齢\n",
        "sibsp\t| タイタニックに同乗している兄弟/配偶者の数\n",
        "parch\t| タイタニックに同乗している親/子供の数\n",
        "fare\t| 料金\n",
        "embarked\t| 出港地（タイタニックへ乗った港）(C=Cherbourg、Q=Queenstown、S=Southampton)\n",
        "class | 乗船クラス\n",
        "who |男性 or 女性\n",
        "adult_male | 成人男性であるかどうか\n",
        "deck | 乗船していたデッキ\n",
        "embark_town | 出港地\n",
        "alive | 生存したかどうか（ survived と同じ意味の項目）\n",
        "alone | 一人であったかどうか"
      ],
      "metadata": {
        "id": "t7UJupBadfY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 欠損値を埋める\n",
        "data['age'] = data['age'].fillna(data['age'].mean() )\n",
        "data['embarked'] = data['embarked'].fillna(data['embarked'].mode()[0] )\n",
        "data['embark_town'] = data['embark_town'].fillna(data['embark_town'].mode()[0] )\n",
        "# 結果を確認\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "_jzkQkrvd8kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "カテゴリ変数の項目に対しては One Hot Encoding を行い、\n",
        "数値型の変数に変換を行う。"
      ],
      "metadata": {
        "id": "PE7WK-g9ffeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# カテゴリ変数をOne Hot Encoding\n",
        "data_encoded = pd.get_dummies(data[['sex', 'embarked', 'class', 'who', 'adult_male', 'alone']], drop_first=True)\n",
        "\n",
        "# 説明変数と目的変数を設定\n",
        "X = pd.concat([data[['age', 'fare', 'sibsp', 'parch']], data_encoded], axis=1)\n",
        "y = data['survived']"
      ],
      "metadata": {
        "id": "p9WKguxbTHe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ハイパーパラメータの max_depth を 2 として決定木を作る。"
      ],
      "metadata": {
        "id": "KkpE3METg9Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを学習用データと検証用データに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 最適なモデルを作成\n",
        "model = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 検証用データで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "um78RN1OSiSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 決定木を可視化する\n",
        "plt.figure(figsize=(10,5))\n",
        "plot_tree(model, filled=True,  fontsize=14, feature_names=X.columns[:-1], class_names=['0(死亡)','1(生存)'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KqOSpXd9b3pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "一番上の who_man は、カテゴリ項目 who を One hot encoding した項目で、\n",
        "who の値が man であれば 1 、そうでないなら 0 になっている。\n",
        "\n",
        "who_man <= 0.5 という不等式なので、0 （すなわち man でない）ならば左側に、\n",
        "1 ならば右側に枝分かれする。\n",
        "\n",
        "例えば、\n",
        "* who = woman\n",
        "* class = Third\n",
        "の場合は「死亡」と予測されることになる。\n"
      ],
      "metadata": {
        "id": "ISLznoFbu63g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ハイパーパラメータチューニング\n",
        "\n",
        "決定木のハイパーパラメータは max_depth である。\n",
        "max_depth を 2から20の範囲で\n",
        "以下のようにグリッドサーチを行う。\n"
      ],
      "metadata": {
        "id": "MJCqr3iMhLj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# ハイパーパラメータの候補\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, 10, 20]\n",
        "    }\n",
        "\n",
        "# グリッドサーチで最適なハイパーパラメータを探す\n",
        "grid_search = GridSearchCV( DecisionTreeClassifier(), param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "q1GBsffU5UGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "最適なパラメータは grid_search.best_estimator_ にセットされる。"
      ],
      "metadata": {
        "id": "bbuhqJ99iSPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "6R1Lgci9aK8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 最適なモデルを作成\n",
        "model = grid_search.best_estimator_\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# テストデータで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "XKZ9OmOGadY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 決定木を可視化する\n",
        "plt.figure(figsize=(15,7))\n",
        "plot_tree(model, filled=True,  fontsize=13, feature_names=X.columns[:-1], class_names=['0(死亡)','1(生存)'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fo8ix57GjX22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "sKSxEjEQyAue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ランダムフォレスト\n",
        "分類問題に対する代表的な機械学習の手法として、\n",
        "**「ランダムフォレスト」**の使い方を説明する。\n",
        "\n",
        "ランダムフォレストは、決定木を複雑に組み合わせた構造を持ち、\n",
        "高い予測精度となるように工夫されてる。\n",
        "また、カテゴリ型の予測だけでなく\n",
        "数値型の予測も行える高精度な万能な予測手法である。\n",
        "ビジネスでも多く用いられている手法である。\n",
        "\n",
        "ただし、決定木のように予測の内部構造を可視化することができない。\n",
        "また、ランダムフォレストを利用するためには、\n",
        "複数のハイパーパラメータの調整が必要で、\n",
        "他の機械学習法と比べて多くの計算時間を必要とする。\n"
      ],
      "metadata": {
        "id": "-LjhwtSgB3va"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ランダムフォレストモデルを学習する"
      ],
      "metadata": {
        "id": "N0DJ5GwBB3vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "モデル構築の手順は決定木と同様で、\n",
        "以下のように変数 model に RandomForestClassifier() をセットした後、\n",
        " fit で学習を行う。\n",
        "```\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(説明変数, 目的変数)\n",
        "```\n",
        "\n",
        "Titanic データを使いランダムフォレストモデルの予測精度を評価する。"
      ],
      "metadata": {
        "id": "ryOuMaiEB3vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ランダムフォレストに必要なライブラリー\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ランダムフォレストの準備（初期設定）\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# 学習\n",
        "model.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "l1bfdIMxB3vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 評価データで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "UKXQlC4kB3vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 変数の重要度\n",
        "\n",
        "ランダムフォレストでは、説明変数の重要度を表示できる。\n",
        "値が大きいほど、予測精度に寄与する度合いが大きいことを意味している。\n",
        "逆に、\n",
        "重要度の小さな変数は、それを用いなくてもほとんど精度に影響がない変数である。\n",
        "また、重要度の値は全て正となり、回帰係数とは異なる意味合いの物である。"
      ],
      "metadata": {
        "id": "SoZUfZShB3vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.feature_importances_"
      ],
      "metadata": {
        "id": "kXoL1pMwB3vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量の重要度を可視化\n",
        "sns.barplot(x=model.feature_importances_, y=X.columns)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O8phEcnwB3vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ハイパーパラメータチューニング\n",
        "\n",
        "ランダムフォレストを利用するためには、\n",
        "いくつかのハイパーパラメータを適切に設定する必要がある。\n",
        "上の例ではデフォルト値が用いられているが、\n",
        "変更することでより精度を向上させることが可能である。\n",
        "\n",
        "調整することで精度の向上が期待できるパラメーターには以下のものがある。\n",
        "\n",
        "*  n_estimators（木の数）: 10 ～ 1000 程度\n",
        "*  max_depth（木の深さ） : 3 ～ 100 程度\n",
        "*  min_samples_split（分割の最小のサンプル数）: 2 ～ 100 程度"
      ],
      "metadata": {
        "id": "LnnPimVGB3vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ランダムフォレストに必要なライブラリー\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ハイパーパラメータの候補\n",
        "param_grid = {\n",
        "    'n_estimators': [20, 50],\n",
        "    'max_depth': [3, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# グリッドサーチで最適なハイパーパラメータを探す\n",
        "grid_search = GridSearchCV( RandomForestClassifier(random_state=42), param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 最適なハイパーパラメータを出力\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n",
        "\n",
        "# 最適なモデルを作成\n",
        "model = grid_search.best_estimator_\n",
        "\n",
        "# 学習\n",
        "model.fit(X_train, y_train.values.ravel())\n"
      ],
      "metadata": {
        "id": "d7LavvorB3vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 精度の評価\n",
        "\n",
        "評価用のデータセットを用いて精度の評価を行う。\n"
      ],
      "metadata": {
        "id": "Qgee4DKUB3vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 評価データで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "m3mIlrVJB3vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "検証用データの場合で、混同行列を作成する。"
      ],
      "metadata": {
        "id": "9QnbWB2OB3vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_val, y_pred)"
      ],
      "metadata": {
        "id": "_-4BQGZAB3vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "D2u9eGlQai1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#【参考】詳しい説明が書かれたサイト\n",
        "\n",
        "各モジュールの詳しい使い方は以下のサイトに記載されている。\n",
        "\n",
        "* 決定木 https://scikit-learn.org/stable/api/sklearn.tree.html\n",
        "\n",
        "* ランダムフォレスト\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n"
      ],
      "metadata": {
        "id": "JCJUulT9-jTY"
      }
    }
  ]
}